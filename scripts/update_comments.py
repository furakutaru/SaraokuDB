#!/usr/bin/env python3
"""
æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ›´æ–°ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ä¿®æ­£ã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆå–å¾—ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ã€å…¨é¦¬ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å†å–å¾—ãƒ»æ›´æ–°
"""

import json
import os
import sys
import requests
from bs4 import BeautifulSoup
import time
from typing import Dict, List

# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend', 'scrapers'))
from rakuten_scraper import RakutenAuctionScraper

def update_comments():
    """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ›´æ–°"""
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®çµ¶å¯¾ãƒ‘ã‚¹ã‚’ä½¿ç”¨
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    history_file = os.path.join(project_root, "static-frontend", "public", "data", "horses_history.json")
    
    print(f"=== ã‚³ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿æ›´æ–°é–‹å§‹ ===")
    print(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {history_file}")
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    try:
        with open(history_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {history_file}")
        return False
    except json.JSONDecodeError as e:
        print(f"ã‚¨ãƒ©ãƒ¼: JSONã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return False
    
    horses = data.get('horses', [])
    print(f"ç·é¦¬æ•°: {len(horses)}é ­")
    
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    scraper = RakutenAuctionScraper()
    
    # å„é¦¬ã®ã‚³ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
    updated_count = 0
    failed_count = 0
    already_has_comment_count = 0
    
    for i, horse in enumerate(horses):
        horse_name = horse.get('name', 'Unknown')
        detail_url = horse.get('detail_url')
        
        print(f"\n{i+1}/{len(horses)}. {horse_name}:")
        
        if not detail_url:
            print("   âŒ detail_urlãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            failed_count += 1
            continue
        
        # å±¥æ­´å†…ã®å…¨ã¦ã®ã‚¨ãƒ³ãƒˆãƒªã§ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç¢ºèªãƒ»æ›´æ–°
        history = horse.get('history', [])
        entry_updated = False
        
        for j, entry in enumerate(history):
            current_comment = entry.get('comment', '')
            
            # æ—¢ã«ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¼·åˆ¶æ›´æ–°ã‚‚å¯èƒ½ï¼‰
            if current_comment and len(current_comment.strip()) > 10:
                if not entry_updated:
                    print(f"   âœ… æ—¢ã«ã‚³ãƒ¡ãƒ³ãƒˆãŒå­˜åœ¨ã—ã¾ã™ï¼ˆ{len(current_comment)}æ–‡å­—ï¼‰")
                    already_has_comment_count += 1
                    entry_updated = True
                continue
            
            try:
                # ãƒšãƒ¼ã‚¸ã‚’å–å¾—ã—ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡º
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
                response = requests.get(detail_url, headers=headers, timeout=10)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                extracted_comment = scraper._extract_comment(soup)
                
                if extracted_comment and len(extracted_comment.strip()) > 0:
                    entry['comment'] = extracted_comment
                    if not entry_updated:
                        print(f"   âœ… ã‚³ãƒ¡ãƒ³ãƒˆæ›´æ–°æˆåŠŸï¼ˆ{len(extracted_comment)}æ–‡å­—ï¼‰")
                        updated_count += 1
                        entry_updated = True
                else:
                    if not entry_updated:
                        print("   âŒ ã‚³ãƒ¡ãƒ³ãƒˆãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
                        failed_count += 1
                        entry_updated = True
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãŸã‚å°‘ã—å¾…æ©Ÿ
                time.sleep(1)
                
            except Exception as e:
                if not entry_updated:
                    print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                    failed_count += 1
                    entry_updated = True
    
    print(f"\n=== æ›´æ–°çµæœ ===")
    print(f"ã‚³ãƒ¡ãƒ³ãƒˆæ›´æ–°æˆåŠŸ: {updated_count}é ­")
    print(f"æ—¢ã«ã‚³ãƒ¡ãƒ³ãƒˆæœ‰ã‚Š: {already_has_comment_count}é ­")
    print(f"æ›´æ–°å¤±æ•—: {failed_count}é ­")
    
    # æ›´æ–°ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    if updated_count > 0:
        try:
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸ: {history_file}")
            return True
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return False
    else:
        print("\nâœ… æ›´æ–°ã®å¿…è¦ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return True

if __name__ == "__main__":
    success = update_comments()
    if success:
        print("\nğŸ‰ ã‚³ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    else:
        print("\nâŒ ã‚³ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ")
