#!/usr/bin/env python3
"""
ç©ã¿ä¸Šã’å‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã—ã¤ã¤æ–°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
- åŒä¸€é¦¬ã®è¤‡æ•°å›å‡ºå“ã«å¯¾å¿œã—ãŸå±¥æ­´ç®¡ç†
- è©³ç´°ãƒšãƒ¼ã‚¸URLå–å¾—ãƒ»ä¿æŒ
"""

import json
import os
import sys
import argparse
from datetime import datetime
from typing import List, Dict, Optional, Tuple
import importlib.util

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(__file__))
sys.path.append(project_root)
sys.path.append(os.path.join(project_root, 'backend'))
sys.path.append(os.path.join(project_root, 'backend/scrapers'))

# æ¥½å¤©ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from scripts.improved_scraper import ImprovedRakutenScraper
except ImportError as e:
    print(f"Error importing ImprovedRakutenScraper: {e}")
    raise


class AccumulativeScraper:
    def __init__(self, enable_history=None, mode='development'):
        self.scraper = ImprovedRakutenScraper()
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®çµ¶å¯¾ãƒ‘ã‚¹ã‚’ä½¿ç”¨
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(script_dir)
        self.history_file = os.path.join(project_root, "static-frontend", "public", "data", "horses_history.json")
        
        # å±¥æ­´ç®¡ç†ã®åˆ¶å¾¡è¨­å®š
        self.mode = mode
        if enable_history is not None:
            self.enable_history = enable_history
        else:
            # ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ãƒ¢ãƒ¼ãƒ‰ã§åˆ¶å¾¡
            env_history = os.getenv('ENABLE_HISTORY_TRACKING', '').lower()
            if env_history in ['true', '1', 'yes']:
                self.enable_history = True
            elif env_history in ['false', '0', 'no']:
                self.enable_history = False
            else:
                # ãƒ¢ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®åˆ¶å¾¡
                self.enable_history = mode in ['production', 'prod']
        
        print(f"å±¥æ­´è¿½åŠ ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if self.enable_history else 'ç„¡åŠ¹'} (mode: {mode})")
        
    def load_existing_data(self) -> Dict:
        """æ—¢å­˜ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        if not os.path.exists(self.history_file):
            return {
                "metadata": {
                    "last_updated": datetime.now().isoformat(),
                    "total_horses": 0,
                    "average_price": 0
                },
                "horses": []
            }
        
        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            return {
                "metadata": {
                    "last_updated": datetime.now().isoformat(),
                    "total_horses": 0,
                    "average_price": 0
                },
                "horses": []
            }
    
    def normalize_name(self, name: str) -> str:
        """é¦¬åã®æ­£è¦åŒ–ï¼ˆæ¯”è¼ƒç”¨ï¼‰"""
        if not name:
            return ""
        return name.strip().replace(" ", "").replace("ã€€", "")
    
    def find_matching_horse(self, new_horse: Dict, existing_horses: List[Dict]) -> Tuple[Optional[int], Optional[Dict]]:
        """
        åŒä¸€é¦¬ã‚’æ¤œç´¢
        åˆ¤å®šåŸºæº–: é¦¬å + è¡€çµ±æƒ…å ±ï¼ˆçˆ¶ã€æ¯ã€æ¯çˆ¶ï¼‰
        """
        new_name = self.normalize_name(new_horse.get('name', ''))
        new_sire = self.normalize_name(new_horse.get('sire', ''))
        new_dam = self.normalize_name(new_horse.get('dam', ''))
        new_dam_sire = self.normalize_name(new_horse.get('dam_sire', ''))
        
        for idx, existing_horse in enumerate(existing_horses):
            # é¦¬åã§ã®ä¸€è‡´ç¢ºèª
            existing_name = self.normalize_name(existing_horse.get('name', ''))
            if existing_name and new_name and existing_name == new_name:
                return idx, existing_horse
            
            # å±¥æ­´å†…ã®é¦¬åã‚‚ç¢ºèª
            for history_entry in existing_horse.get('history', []):
                history_name = self.normalize_name(history_entry.get('name', ''))
                if history_name and new_name and history_name == new_name:
                    return idx, existing_horse
            
            # è¡€çµ±æƒ…å ±ã§ã®ä¸€è‡´ç¢ºèªï¼ˆé¦¬åãŒç•°ãªã‚‹å ´åˆï¼‰
            existing_sire = self.normalize_name(existing_horse.get('sire', ''))
            existing_dam = self.normalize_name(existing_horse.get('dam', ''))
            existing_dam_sire = self.normalize_name(existing_horse.get('dam_sire', ''))
            
            if (new_sire and existing_sire and new_sire == existing_sire and
                new_dam and existing_dam and new_dam == existing_dam and
                new_dam_sire and existing_dam_sire and new_dam_sire == existing_dam_sire):
                return idx, existing_horse
        
        return None, None
    
    def create_history_entry(self, horse_data: Dict, auction_date: str) -> Dict:
        """å±¥æ­´ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆ
        
        Args:
            horse_data: é¦¬ã®ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€è¾æ›¸
            auction_date: ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
            
        Returns:
            æ–°ã—ã„å±¥æ­´ã‚¨ãƒ³ãƒˆãƒªã‚’å«ã‚€è¾æ›¸
        """
        # è¡€çµ±æƒ…å ±ã‚’çµ±ä¸€ï¼ˆdamsire ã¨ dam_sire ã®ä¸¡æ–¹ã«åŒã˜å€¤ã‚’è¨­å®šï¼‰
        damsire = horse_data.get('damsire') or horse_data.get('dam_sire', '')
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
        default_values = {
            # åŸºæœ¬æƒ…å ±
            'name': horse_data.get('name', ''),
            'sex': horse_data.get('sex', ''),
            'age': horse_data.get('age', 0),
            'seller': horse_data.get('seller', ''),
            'auction_date': auction_date,
            
            # è¡€çµ±æƒ…å ±
            'sire': horse_data.get('sire', ''),
            'dam': horse_data.get('dam', ''),
            'damsire': damsire,
            'dam_sire': damsire,  # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚
            
            # ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±
            'sold_price': horse_data.get('sold_price'),
            'start_price': horse_data.get('start_price'),
            'bid_num': horse_data.get('bid_num', 0),
            'unsold': horse_data.get('unsold', False),
            
            # ãã®ä»–ã®æƒ…å ±
            'comment': horse_data.get('comment', ''),
            'disease_tags': horse_data.get('disease_tags', []),
            'weight': horse_data.get('weight'),
            'race_record': horse_data.get('race_record', {}),
            'total_prize_start': horse_data.get('total_prize_start', 0),
            'total_prize_latest': horse_data.get('total_prize_latest', 0),
            
            # URLæƒ…å ±
            'jbis_url': horse_data.get('jbis_url', ''),
            'netkeiba_url': horse_data.get('netkeiba_url', ''),  # ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«
            'detail_url': horse_data.get('detail_url', ''),
            'primary_image': horse_data.get('primary_image', '')
        }
        
        # ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³æ—¥ã‚’è¨­å®š
        default_values['auction_date'] = auction_date
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä½œæˆã—ãŸã‚¨ãƒ³ãƒˆãƒªã‚’è¡¨ç¤º
        print(f"å±¥æ­´ã‚¨ãƒ³ãƒˆãƒªä½œæˆ: {default_values['name'] or 'Unknown'} - {auction_date}")
        print(f"  æ€§åˆ¥: {default_values['sex']}, å¹´é½¢: {default_values['age']}, è²©å£²è€…: {default_values['seller']}")
        print(f"  é¦¬ä½“é‡: {default_values['weight']}kg, è³é‡‘: {default_values['total_prize_latest']}ä¸‡å††, ã‚³ãƒ¡ãƒ³ãƒˆé•·: {len(default_values['comment'])}æ–‡å­—")
        print(f"  ç—…æ°—ã‚¿ã‚°: {default_values['disease_tags']}")
        
        return default_values
    
    def merge_horse_data(self, existing_horse: Dict, new_horse: Dict, auction_date: str) -> Dict:
        """æ—¢å­˜é¦¬ãƒ‡ãƒ¼ã‚¿ã«æ–°ã—ã„å±¥æ­´ã‚’è¿½åŠ 
        
        Args:
            existing_horse: æ—¢å­˜ã®é¦¬ãƒ‡ãƒ¼ã‚¿
            new_horse: æ–°ã—ã„é¦¬ãƒ‡ãƒ¼ã‚¿
            auction_date: ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
            
        Returns:
            æ›´æ–°ã•ã‚ŒãŸé¦¬ãƒ‡ãƒ¼ã‚¿
        """
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒªã‚¹ãƒˆã‚’å®šç¾©ï¼ˆå„ªå…ˆåº¦é †ï¼‰
        required_fields = [
            'sex', 'age', 'seller', 'sire', 'dam', 'damsire', 'dam_sire', 
            'jbis_url', 'auction_date', 'name', 'comment', 'disease_tags'
        ]
        
        # æ—¢å­˜ã®å±¥æ­´ã‚’å–å¾—
        history = existing_horse.get('history', [])
        
        # æ–°ã—ã„å±¥æ­´ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆ
        new_history_entry = self.create_history_entry(new_horse, auction_date)
        
        # å±¥æ­´ã«è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
        history_dates = {h.get('auction_date') for h in history}
        if auction_date not in history_dates and self.enable_history:
            history.append(new_history_entry)
            print(f"âœ… å±¥æ­´ã‚’è¿½åŠ : {existing_horse.get('name', 'Unknown')} - {auction_date}")
        else:
            print(f"âš ï¸ å±¥æ­´è¿½åŠ ã‚¹ã‚­ãƒƒãƒ—: {existing_horse.get('name', 'Unknown')} - {auction_date} (ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰)")

        # è¡€çµ±æƒ…å ±ã‚’çµ±ä¸€ï¼ˆdamsire ã¨ dam_sire ã®ä¸¡æ–¹ã«åŒã˜å€¤ã‚’è¨­å®šï¼‰
        damsire = (
            new_horse.get('damsire') or 
            new_horse.get('dam_sire') or 
            existing_horse.get('damsire') or 
            existing_horse.get('dam_sire', '') or
            'ä¸æ˜'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        )
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ›´æ–°ã®å„ªå…ˆé †ä½ã‚’å®šç¾©
        def get_priority_value(field, default=''):
            # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆã€ãªã‘ã‚Œã°æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã€ãã‚Œã‚‚ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            return (
                new_horse.get(field) 
                if field in new_horse and new_horse[field] not in (None, '')
                else existing_horse.get(field, default)
            )
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å€¤ã‚’ç¢ºå®Ÿã«è¨­å®š
        def get_required_field(field):
            # 1. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
            value = new_horse.get(field)
            if value not in (None, ''):
                return value
                
            # 2. æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
            value = existing_horse.get(field)
            if value not in (None, ''):
                return value
                
            # 3. å±¥æ­´ã‹ã‚‰æœ€æ–°ã®æœ‰åŠ¹ãªå€¤ã‚’æ¢ã™
            for h in reversed(history):
                hist_value = h.get(field)
                if hist_value not in (None, ''):
                    return hist_value
            
            # 4. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
            if field == 'age':
                return 0
            elif field == 'auction_date':
                return auction_date
            elif field in ['sire', 'dam', 'damsire', 'dam_sire']:
                return 'ä¸æ˜'
            elif field == 'disease_tags':
                return []
            elif field == 'race_record':
                return {}
            return ''
        
        # æ›´æ–°ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å®šç¾©
        update_fields = {
            # åŸºæœ¬æƒ…å ±
            'name': get_priority_value('name', 'ä¸æ˜'),
            'sex': get_required_field('sex'),
            'age': get_required_field('age'),
            'seller': get_required_field('seller'),
            'auction_date': get_required_field('auction_date'),
            
            # è¡€çµ±æƒ…å ±
            'sire': get_required_field('sire'),
            'dam': get_required_field('dam'),
            'damsire': damsire if damsire != 'ä¸æ˜' else get_required_field('damsire'),
            'dam_sire': damsire if damsire != 'ä¸æ˜' else get_required_field('damsire'),  # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚
            
            # URLæƒ…å ±
            'jbis_url': get_required_field('jbis_url'),
            'netkeiba_url': get_priority_value('netkeiba_url'),  # ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«
            'detail_url': get_priority_value('detail_url', existing_horse.get('detail_url', '')),
            
            # ãã®ä»–ã®æƒ…å ±
            'comment': get_priority_value('comment', ''),
            'disease_tags': get_priority_value('disease_tags', []),
            'primary_image': get_priority_value('primary_image', ''),
            'total_prize_latest': get_priority_value('total_prize_latest', 0),
            'weight': get_priority_value('weight'),
            'race_record': get_priority_value('race_record', {}),
            'updated_at': datetime.now().isoformat(),
            'history': history
        }
        
        # æœ€æ–°ã®ä½“é‡ã‚’ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã«åæ˜ 
        latest_weight = self._get_latest_weight(history)
        if latest_weight is not None:
            update_fields['weight'] = latest_weight
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¤œè¨¼ã¨ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        missing_fields = []
        for field in required_fields:
            value = update_fields.get(field)
            if value in (None, '', 0) and field != 'age':  # age=0ã¯æœ‰åŠ¹
                missing_fields.append(field)
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›
                print(f"âš ï¸ å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³: {field}")
                print(f"  - æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿: {new_horse.get(field)}")
                print(f"  - æ—¢å­˜ãƒ‡ãƒ¼ã‚¿: {existing_horse.get(field)}")
                print(f"  - å±¥æ­´: {[h.get(field) for h in history if h.get(field) not in (None, '')]}")
        
        if missing_fields:
            print(f"âš ï¸ å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_fields)}")
            print(f"  ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®šã—ã¾ã™")
            
            # ä¸è¶³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            for field in missing_fields:
                if field == 'age':
                    update_fields[field] = 0
                elif field == 'auction_date':
                    update_fields[field] = auction_date
                elif field in ['sire', 'dam', 'damsire', 'dam_sire']:
                    update_fields[field] = 'ä¸æ˜'
                elif field == 'disease_tags':
                    update_fields[field] = []
                elif field == 'race_record':
                    update_fields[field] = {}
                else:
                    update_fields[field] = ''
        
        # æ—¢å­˜ã®é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        existing_horse.update(update_fields)
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã«æ›´æ–°ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¡¨ç¤º
        print(f"\n=== é¦¬ãƒ‡ãƒ¼ã‚¿æ›´æ–° (ID: {existing_horse.get('id')}) ===")
        print(f"é¦¬å: {existing_horse.get('name')}")
        print(f"æ€§åˆ¥: {existing_horse.get('sex')}, å¹´é½¢: {existing_horse.get('age')}, è²©å£²è€…: {existing_horse.get('seller')}")
        print(f"è¡€çµ±: {existing_horse.get('sire')} - {existing_horse.get('dam')} (æ¯çˆ¶: {existing_horse.get('damsire')})")
        print(f"JBIS URL: {existing_horse.get('jbis_url')}")
        print(f"ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³æ—¥: {existing_horse.get('auction_date')}")
        print(f"é¦¬ä½“é‡: {existing_horse.get('weight', 'N/A')}kg, è³é‡‘: {existing_horse.get('total_prize_latest', 0)}ä¸‡å††")
        print(f"ã‚³ãƒ¡ãƒ³ãƒˆ: {len(existing_horse.get('comment', ''))}æ–‡å­—, ç—…æ°—ã‚¿ã‚°: {existing_horse.get('disease_tags', [])}")
        print(f"ç”»åƒ: {'ã‚ã‚Š' if existing_horse.get('primary_image') else 'ãªã—'}")
        print(f"å±¥æ­´ã‚¨ãƒ³ãƒˆãƒª: {len(existing_horse.get('history', []))}ä»¶")
        print("=" * 50)
        
        return existing_horse
    
    def clear_history_data(self, backup=True) -> bool:
        """å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ"""
        try:
            if not os.path.exists(self.history_file):
                print("âœ… å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return True
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            if backup:
                backup_file = f"{self.history_file}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                import shutil
                shutil.copy2(self.history_file, backup_file)
                print(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_file}")
            
            # æ–°ã—ã„ç©ºã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ä½œæˆ
            empty_data = {
                "metadata": {
                    "last_updated": datetime.now().isoformat(),
                    "total_horses": 0,
                    "average_price": 0
                },
                "horses": []
            }
            
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(empty_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ: {self.history_file}")
            return True
            
        except Exception as e:
            print(f"âŒ å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—: {e}")
            return False
    
    def restore_from_backup(self, backup_file: str) -> bool:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ"""
        try:
            if not os.path.exists(backup_file):
                print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {backup_file}")
                return False
            
            import shutil
            shutil.copy2(backup_file, self.history_file)
            print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒã—ã¾ã—ãŸ: {backup_file} -> {self.history_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒã«å¤±æ•—: {e}")
            return False
    
    def reset_history_count(self, backup=True, keep_latest_only=True, reset_mode='keep_latest', target_date=None) -> bool:
        """
        å±¥æ­´ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆã—ã€æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ã«å¿œã˜ã¦å±¥æ­´ã‚’ç®¡ç†
        
        Args:
            backup (bool): ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã™ã‚‹ã‹
            keep_latest_only (bool): æœ€æ–°å±¥æ­´ã®ã¿ã‚’ä¿æŒã™ã‚‹ã‹ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰
            reset_mode (str): ãƒªã‚»ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰
                - 'keep_latest': æœ€æ–°å±¥æ­´ã®ã¿ä¿æŒï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
                - 'remove_latest': æœ€æ–°å±¥æ­´ã®ã¿å‰Šé™¤
                - 'keep_oldest': æœ€å¤å±¥æ­´ã®ã¿ä¿æŒ
                - 'remove_oldest': æœ€å¤å±¥æ­´ã®ã¿å‰Šé™¤
                - 'keep_by_date': æŒ‡å®šæ—¥ä»˜ã®å±¥æ­´ã®ã¿ä¿æŒ
                - 'remove_by_date': æŒ‡å®šæ—¥ä»˜ã®å±¥æ­´ã®ã¿å‰Šé™¤
            target_date (str): æ—¥ä»˜æŒ‡å®šãƒ¢ãƒ¼ãƒ‰ç”¨ã®å¯¾è±¡æ—¥ä»˜ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
        """
        try:
            if not os.path.exists(self.history_file):
                print("âŒ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return False
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            if backup:
                backup_file = f"{self.history_file}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                import shutil
                shutil.copy2(self.history_file, backup_file)
                print(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_file}")
            
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            existing_data = self.load_existing_data()
            existing_horses = existing_data.get('horses', [])
            
            if not existing_horses:
                print("âŒ å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return False
            
            # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®keep_latest_onlyã‚’reset_modeã«å¤‰æ›
            if keep_latest_only and reset_mode == 'keep_latest':
                reset_mode = 'keep_latest'
            elif not keep_latest_only and reset_mode == 'keep_latest':
                reset_mode = 'keep_all'  # å…¨å±¥æ­´ä¿æŒ
            
            reset_count = 0
            total_history_before = 0
            total_history_after = 0
            
            print(f"ğŸ”„ å±¥æ­´ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚»ãƒƒãƒˆã‚’é–‹å§‹: {len(existing_horses)}é ­ã®é¦¬ã‚’å‡¦ç†")
            print(f"ğŸ”§ ãƒªã‚»ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰: {reset_mode}")
            if target_date:
                print(f"ğŸ“… å¯¾è±¡æ—¥ä»˜: {target_date}")
            
            for horse in existing_horses:
                history = horse.get('history', [])
                total_history_before += len(history)
                original_count = len(history)
                
                if len(history) <= 1:
                    # å±¥æ­´ãŒ1ä»¶ä»¥ä¸‹ã®å ´åˆã¯å‡¦ç†ã—ãªã„
                    total_history_after += len(history)
                    continue
                
                new_history = self._filter_history_by_mode(history, reset_mode, target_date)
                
                if len(new_history) != original_count:
                    horse['history'] = new_history
                    reset_count += 1
                    total_history_after += len(new_history)
                    print(f"  âœ… {horse.get('name', 'Unknown')}: {original_count}ä»¶ -> {len(new_history)}ä»¶")
                else:
                    total_history_after += len(history)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
            updated_data = {
                "metadata": {
                    "last_updated": datetime.now().isoformat(),
                    "total_horses": len(existing_horses),
                    "average_price": existing_data.get('metadata', {}).get('average_price', 0),
                    "auction_date": datetime.now().strftime('%Y-%m-%d'),
                    "history_reset": True,
                    "reset_date": datetime.now().isoformat(),
                    "horses_reset": reset_count,
                    "total_history_before": total_history_before,
                    "total_history_after": total_history_after
                },
                "horses": existing_horses
            }
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(updated_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å±¥æ­´ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚»ãƒƒãƒˆãŒå®Œäº†ã—ã¾ã—ãŸ")
            print(f"  ãƒªã‚»ãƒƒãƒˆå¯¾è±¡: {reset_count}é ­")
            print(f"  å±¥æ­´æ•°: {total_history_before}ä»¶ -> {total_history_after}ä»¶")
            print(f"  ä¿å­˜å…ˆ: {self.history_file}")
            
            return True
            
        except Exception as e:
            print(f"âŒ å±¥æ­´ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚»ãƒƒãƒˆã«å¤±æ•—: {e}")
            return False
    
    def _filter_history_by_mode(self, history: List[Dict], reset_mode: str, target_date: str = None) -> List[Dict]:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦å±¥æ­´ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        Args:
            history (List[Dict]): å…ƒã®å±¥æ­´ãƒªã‚¹ãƒˆ
            reset_mode (str): ãƒªã‚»ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰
            target_date (str): æ—¥ä»˜æŒ‡å®šãƒ¢ãƒ¼ãƒ‰ç”¨ã®å¯¾è±¡æ—¥ä»˜
            
        Returns:
            List[Dict]: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®å±¥æ­´ãƒªã‚¹ãƒˆ
        """
        if not history:
            return history
        
        # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆã—ãŸå±¥æ­´ã‚’ä½œæˆ
        sorted_history = sorted(history, key=lambda x: x.get('auction_date', ''))
        
        if reset_mode == 'keep_latest':
            # æœ€æ–°ã®å±¥æ­´ã®ã¿ä¿æŒ
            return [sorted_history[-1]] if sorted_history else []
        
        elif reset_mode == 'remove_latest':
            # æœ€æ–°ã®å±¥æ­´ã®ã¿å‰Šé™¤
            return sorted_history[:-1] if len(sorted_history) > 1 else []
        
        elif reset_mode == 'keep_oldest':
            # æœ€å¤ã®å±¥æ­´ã®ã¿ä¿æŒ
            return [sorted_history[0]] if sorted_history else []
        
        elif reset_mode == 'remove_oldest':
            # æœ€å¤ã®å±¥æ­´ã®ã¿å‰Šé™¤
            return sorted_history[1:] if len(sorted_history) > 1 else []
        
        elif reset_mode == 'keep_by_date':
            # æŒ‡å®šæ—¥ä»˜ã®å±¥æ­´ã®ã¿ä¿æŒ
            if not target_date:
                print(f"âš ï¸  æ—¥ä»˜æŒ‡å®šãƒ¢ãƒ¼ãƒ‰ã§ã™ãŒå¯¾è±¡æ—¥ä»˜ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return history
            return [h for h in history if h.get('auction_date') == target_date]
        
        elif reset_mode == 'remove_by_date':
            # æŒ‡å®šæ—¥ä»˜ã®å±¥æ­´ã®ã¿å‰Šé™¤
            if not target_date:
                print(f"âš ï¸  æ—¥ä»˜æŒ‡å®šãƒ¢ãƒ¼ãƒ‰ã§ã™ãŒå¯¾è±¡æ—¥ä»˜ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return history
            return [h for h in history if h.get('auction_date') != target_date]
        
        elif reset_mode == 'keep_all':
            # å…¨å±¥æ­´ä¿æŒï¼ˆãƒªã‚»ãƒƒãƒˆã—ãªã„ï¼‰
            return history
        
        else:
            print(f"âš ï¸  ä¸æ˜ãªãƒªã‚»ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰: {reset_mode}")
            return history
    
    def _get_latest_weight(self, history: List[Dict]) -> Optional[int]:
        """å±¥æ­´ã‹ã‚‰æœ€æ–°ã®ä½“é‡ã‚’å–å¾—"""
        if not history:
            return None
        
        # å±¥æ­´ã‚’æ—¥ä»˜é †ã§ã‚½ãƒ¼ãƒˆï¼ˆæœ€æ–°ãŒæœ€å¾Œï¼‰
        sorted_history = sorted(history, key=lambda x: x.get('auction_date', ''))
        
        # æœ€æ–°ã®å±¥æ­´ã‹ã‚‰ä½“é‡ã‚’å–å¾—
        for entry in reversed(sorted_history):
            weight = entry.get('weight')
            if weight is not None:
                return weight
        
        return None
    
    def create_new_horse_entry(self, horse_data: Dict, auction_date: str, horse_id: int) -> Dict:
        """æ–°ã—ã„é¦¬ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆ
        
        Args:
            horse_data: é¦¬ã®ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€è¾æ›¸
            auction_date: ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
            horse_id: é¦¬ã®ä¸€æ„ã®ID
            
        Returns:
            æ–°ã—ã„é¦¬ã‚¨ãƒ³ãƒˆãƒªã‚’å«ã‚€è¾æ›¸
        """
        # è¡€çµ±æƒ…å ±ã‚’çµ±ä¸€ï¼ˆdamsire ã¨ dam_sire ã®ä¸¡æ–¹ã«åŒã˜å€¤ã‚’è¨­å®šï¼‰
        damsire = horse_data.get('damsire') or horse_data.get('dam_sire', '')
        
        # æ–°ã—ã„é¦¬ã‚¨ãƒ³ãƒˆãƒªã®åŸºæœ¬æƒ…å ±
        new_entry = {
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            'id': horse_id,
            'name': horse_data.get('name', ''),
            'sex': horse_data.get('sex', ''),
            'age': horse_data.get('age', 0),
            'seller': horse_data.get('seller', ''),
            'sire': horse_data.get('sire', ''),
            'dam': horse_data.get('dam', ''),
            'damsire': damsire,
            'dam_sire': damsire,  # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚
            'jbis_url': horse_data.get('jbis_url', ''),
            'auction_date': horse_data.get('auction_date', auction_date),
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat(),
            'history': [],
            
            # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            'netkeiba_url': horse_data.get('netkeiba_url', ''),  # ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«
            'detail_url': horse_data.get('detail_url', ''),
            'comment': horse_data.get('comment', ''),
            'disease_tags': horse_data.get('disease_tags', []),
            'primary_image': horse_data.get('primary_image', ''),
            'total_prize_latest': horse_data.get('total_prize_latest', 0),
            'weight': horse_data.get('weight'),
            'race_record': horse_data.get('race_record', {})
        }
        
        # å±¥æ­´ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆï¼ˆå¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒç¢ºå®Ÿã«å«ã¾ã‚Œã‚‹ã‚ˆã†ã«ï¼‰
        history_entry = self.create_history_entry(new_entry, new_entry['auction_date'])
        new_entry['history'].append(history_entry)
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä½œæˆã—ãŸã‚¨ãƒ³ãƒˆãƒªã‚’è¡¨ç¤º
        print(f"\n=== æ–°è¦é¦¬ã‚¨ãƒ³ãƒˆãƒªä½œæˆ (ID: {horse_id}) ===")
        print(f"é¦¬å: {new_entry['name']}")
        print(f"æ€§åˆ¥: {new_entry['sex']}, å¹´é½¢: {new_entry['age']}, è²©å£²è€…: {new_entry['seller']}")
        print(f"çˆ¶: {new_entry['sire']}, æ¯: {new_entry['dam']}, æ¯çˆ¶: {new_entry['damsire']}")
        print(f"JBIS URL: {new_entry['jbis_url']}")
        print(f"ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³æ—¥: {new_entry['auction_date']}")
        print(f"é¦¬ä½“é‡: {new_entry.get('weight', 'N/A')}kg")
        print(f"ç·è³é‡‘: {new_entry.get('total_prize_latest', 0)}ä¸‡å††")
        print(f"ã‚³ãƒ¡ãƒ³ãƒˆé•·: {len(new_entry.get('comment', ''))}æ–‡å­—")
        print(f"ç—…æ°—ã‚¿ã‚°: {new_entry.get('disease_tags', [])}")
        print("=" * 50)
        print(f"JBIS URL: {new_entry['jbis_url']}")
        print(f"Netkeiba URL: {new_entry['netkeiba_url']}")
        print(f"ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³æ—¥: {new_entry['auction_date']}")
        print(f"é¦¬ä½“é‡: {new_entry.get('weight')}kg, è³é‡‘: {new_entry['total_prize_latest']}ä¸‡å††")
        print(f"ã‚³ãƒ¡ãƒ³ãƒˆé•·: {len(new_entry['comment'])}æ–‡å­—, ç—…æ°—ã‚¿ã‚°: {new_entry['disease_tags']}")
        
        return new_entry
    
    def scrape_and_accumulate(self) -> bool:
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œï¼‹ãƒ‡ãƒ¼ã‚¿ç©ã¿ä¸Šã’
        
        Returns:
            bool: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¨ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ãŒæˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        print("=== ç©ã¿ä¸Šã’å‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹ ===")
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        existing_data = self.load_existing_data()
        existing_horses = existing_data.get('horses', [])
        
        print(f"æ—¢å­˜é¦¬ãƒ‡ãƒ¼ã‚¿: {len(existing_horses)}é ­")
        
        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
        print("æ–°ã—ã„ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        new_horses = self.scraper.scrape_all_horses()
        
        if not new_horses:
            print("æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return False
        
        print(f"æ–°è¦å–å¾—: {len(new_horses)}é ­")
        
        # ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³æ—¥ã‚’å–å¾—
        auction_date = self.scraper.get_auction_date()
        
        # ãƒ‡ãƒ¼ã‚¿çµ±åˆå‡¦ç†
        added_count = 0
        updated_count = 0
        next_id = max([h.get('id', 0) for h in existing_horses], default=0) + 1
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã«æ–°ã—ã„é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
        print("\n=== æ–°è¦å–å¾—ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒãƒªãƒ¼ ===")
        for i, horse in enumerate(new_horses, 1):
            print(f"{i}. {horse.get('name')} - æ€§åˆ¥: {horse.get('sex')}, å¹´é½¢: {horse.get('age')}, è²©å£²è€…: {horse.get('seller')}")
            print(f"   çˆ¶: {horse.get('sire')}, æ¯: {horse.get('dam')}, æ¯çˆ¶: {horse.get('damsire') or horse.get('dam_sire')}")
        
        print("\n=== ãƒ‡ãƒ¼ã‚¿çµ±åˆå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ ===")
        
        for new_horse in new_horses:
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            default_values = {
                'comment': '',
                'disease_tags': [],
                'total_prize_latest': 0,
                'primary_image': '',
                'race_record': {}
            }
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§ä¸Šæ›¸ãï¼ˆæ—¢å­˜ã®å€¤ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ï¼‰
            for key, default in default_values.items():
                if key not in new_horse:
                    new_horse[key] = default
            
            # åŒä¸€é¦¬ã‚’æ¤œç´¢
            match_idx, existing_horse = self.find_matching_horse(new_horse, existing_horses)
            
            if existing_horse is not None:
                # æ—¢å­˜é¦¬ã®å±¥æ­´ã‚’æ›´æ–°
                print(f"\n=== æ—¢å­˜é¦¬ã®å±¥æ­´ã‚’æ›´æ–°: {new_horse.get('name')} (ID: {existing_horse.get('id')}) ===")
                updated_horse = self.merge_horse_data(existing_horse, new_horse, auction_date)
                existing_horses[match_idx] = updated_horse
                updated_count += 1
            else:
                # æ–°ã—ã„é¦¬ã¨ã—ã¦è¿½åŠ 
                print(f"\n=== æ–°è¦é¦¬ã‚’è¿½åŠ : {new_horse.get('name')} (ID: {next_id}) ===")
                new_entry = self.create_new_horse_entry(new_horse, auction_date, next_id)
                existing_horses.append(new_entry)
                next_id += 1
                added_count += 1
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
        total_horses = len(existing_horses)
        all_prices = []
        for horse in existing_horses:
            for history in horse.get('history', []):
                price = history.get('sold_price')
                if price and not history.get('unsold', False):
                    all_prices.append(price)
        
        avg_price = sum(all_prices) / len(all_prices) if all_prices else 0
        
        updated_data = {
            "metadata": {
                "last_updated": datetime.now().isoformat(),
                "total_horses": total_horses,
                "average_price": int(avg_price),
                "auction_date": auction_date,
                "added_horses": added_count,
                "updated_horses": updated_count
            },
            "horses": existing_horses
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        print(f"ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {os.path.dirname(self.history_file)}")
        os.makedirs(os.path.dirname(self.history_file), exist_ok=True)
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜é–‹å§‹: {self.history_file}")
        print(f"ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: é¦¬æ•°={len(existing_horses)}, ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿={updated_data['metadata']}")
        
        with open(self.history_file, 'w', encoding='utf-8') as f:
            json.dump(updated_data, f, ensure_ascii=False, indent=2)
        
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {self.history_file}")
        
        # ä¿å­˜ç¢ºèª
        if os.path.exists(self.history_file):
            file_size = os.path.getsize(self.history_file)
            print(f"ä¿å­˜ç¢ºèªOK: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º={file_size}ãƒã‚¤ãƒˆ")
        else:
            print(f"[ã‚¨ãƒ©ãƒ¼] ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«å¤±æ•—: {self.history_file}")
        
        print(f"=== ç©ã¿ä¸Šã’å®Œäº† ===")
        print(f"æ–°è¦è¿½åŠ : {added_count}é ­")
        print(f"å±¥æ­´æ›´æ–°: {updated_count}é ­")
        print(f"ç·é¦¬æ•°: {total_horses}é ­")
        print(f"ä¿å­˜å…ˆ: {self.history_file}")
        
        return True


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='ç©ã¿ä¸Šã’å‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ï¼ˆå±¥æ­´è¿½åŠ æœ‰åŠ¹ï¼‰
  python3 accumulative_scraper.py --mode production
  
  # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆå±¥æ­´è¿½åŠ ç„¡åŠ¹ï¼‰
  python3 accumulative_scraper.py --mode test
  
  # ç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡
  ENABLE_HISTORY_TRACKING=true python3 accumulative_scraper.py
  
  # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä»˜ãï¼‰
  python3 accumulative_scraper.py --clear-data
  
  # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ
  python3 accumulative_scraper.py --restore backup_file.json
  
  # å±¥æ­´ãƒªã‚»ãƒƒãƒˆä¾‹:
  # æœ€æ–°å±¥æ­´ã®ã¿ä¿æŒï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
  python3 accumulative_scraper.py --reset-history
  
  # æœ€æ–°å±¥æ­´ã®ã¿å‰Šé™¤ï¼ˆå¤ã„ãƒ‡ãƒ¼ã‚¿ã®ã¿ä¿æŒï¼‰
  python3 accumulative_scraper.py --reset-history --reset-mode remove_latest
  
  # æœ€å¤å±¥æ­´ã®ã¿ä¿æŒ
  python3 accumulative_scraper.py --reset-history --reset-mode keep_oldest
  
  # æœ€å¤å±¥æ­´ã®ã¿å‰Šé™¤
  python3 accumulative_scraper.py --reset-history --reset-mode remove_oldest
  
  # ç‰¹å®šæ—¥ä»˜ã®å±¥æ­´ã®ã¿ä¿æŒ
  python3 accumulative_scraper.py --reset-history --reset-mode keep_by_date --target-date 2025-07-25
  
  # ç‰¹å®šæ—¥ä»˜ã®å±¥æ­´ã®ã¿å‰Šé™¤
  python3 accumulative_scraper.py --reset-history --reset-mode remove_by_date --target-date 2025-07-25
        """
    )
    
    parser.add_argument(
        '--mode', 
        choices=['production', 'prod', 'development', 'dev', 'test'],
        default='development',
        help='å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ (production: å±¥æ­´è¿½åŠ æœ‰åŠ¹, test/development: å±¥æ­´è¿½åŠ ç„¡åŠ¹)'
    )
    
    parser.add_argument(
        '--enable-history',
        action='store_true',
        help='å±¥æ­´è¿½åŠ ã‚’å¼·åˆ¶çš„ã«æœ‰åŠ¹åŒ–'
    )
    
    parser.add_argument(
        '--disable-history',
        action='store_true', 
        help='å±¥æ­´è¿½åŠ ã‚’å¼·åˆ¶çš„ã«ç„¡åŠ¹åŒ–'
    )
    
    parser.add_argument(
        '--clear-data',
        action='store_true',
        help='å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆï¼‰'
    )
    
    parser.add_argument(
        '--restore',
        metavar='BACKUP_FILE',
        help='ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ'
    )
    
    parser.add_argument(
        '--no-backup',
        action='store_true',
        help='ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢æ™‚ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ãªã„'
    )
    
    parser.add_argument(
        '--reset-history',
        action='store_true',
        help='å±¥æ­´ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆæœ€æ–°å±¥æ­´ã®ã¿ä¿æŒï¼‰'
    )
    
    parser.add_argument(
        '--keep-all-history',
        action='store_true',
        help='å±¥æ­´ãƒªã‚»ãƒƒãƒˆæ™‚ã«å…¨å±¥æ­´ã‚’ä¿æŒï¼ˆã‚«ã‚¦ãƒ³ãƒˆã®ã¿ãƒªã‚»ãƒƒãƒˆï¼‰'
    )
    
    parser.add_argument(
        '--reset-mode',
        choices=['keep_latest', 'remove_latest', 'keep_oldest', 'remove_oldest', 'keep_by_date', 'remove_by_date'],
        default='keep_latest',
        help='å±¥æ­´ãƒªã‚»ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’æŒ‡å®š'
    )
    
    parser.add_argument(
        '--target-date',
        metavar='YYYY-MM-DD',
        help='æ—¥ä»˜æŒ‡å®šãƒ¢ãƒ¼ãƒ‰ç”¨ã®å¯¾è±¡æ—¥ä»˜ï¼ˆkeep_by_date/remove_by_dateã§ä½¿ç”¨ï¼‰'
    )
    
    args = parser.parse_args()
    
    # å±¥æ­´è¿½åŠ ã®åˆ¶å¾¡è¨­å®š
    enable_history = None
    if args.enable_history:
        enable_history = True
    elif args.disable_history:
        enable_history = False
    
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    scraper = AccumulativeScraper(enable_history=enable_history, mode=args.mode)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢å‡¦ç†
    if args.clear_data:
        print("ğŸ—‘ï¸  å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªã‚¢ã‚’å®Ÿè¡Œä¸­...")
        success = scraper.clear_history_data(backup=not args.no_backup)
        if success:
            print("âœ… å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªã‚¢ãŒå®Œäº†ã—ã¾ã—ãŸ")
        else:
            print("âŒ å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
        return
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒå‡¦ç†
    if args.restore:
        print(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒã‚’å®Ÿè¡Œä¸­: {args.restore}")
        success = scraper.restore_from_backup(args.restore)
        if success:
            print("âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒãŒå®Œäº†ã—ã¾ã—ãŸ")
        else:
            print("âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
        return
    
    # å±¥æ­´ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚»ãƒƒãƒˆå‡¦ç†
    if args.reset_history:
        print("ğŸ”„ å±¥æ­´ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚»ãƒƒãƒˆã‚’å®Ÿè¡Œä¸­...")
        
        # ãƒªã‚»ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã®æ±ºå®š
        reset_mode = args.reset_mode
        if args.keep_all_history:
            reset_mode = 'keep_all'
        
        # æ—¥ä»˜æŒ‡å®šãƒ¢ãƒ¼ãƒ‰ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if reset_mode in ['keep_by_date', 'remove_by_date'] and not args.target_date:
            print("âŒ æ—¥ä»˜æŒ‡å®šãƒ¢ãƒ¼ãƒ‰ã§ã¯ --target-date ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒå¿…è¦ã§ã™")
            sys.exit(1)
        
        # æ—¥ä»˜å½¢å¼ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if args.target_date:
            import re
            if not re.match(r'\d{4}-\d{2}-\d{2}', args.target_date):
                print("âŒ æ—¥ä»˜ã¯ YYYY-MM-DD å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„")
                sys.exit(1)
        
        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®keep_latest_onlyã‚’è¨­å®š
        keep_latest_only = (reset_mode == 'keep_latest')
        
        success = scraper.reset_history_count(
            backup=not args.no_backup, 
            keep_latest_only=keep_latest_only,
            reset_mode=reset_mode,
            target_date=args.target_date
        )
        
        if success:
            mode_descriptions = {
                'keep_latest': 'æœ€æ–°å±¥æ­´ã®ã¿ä¿æŒ',
                'remove_latest': 'æœ€æ–°å±¥æ­´ã®ã¿å‰Šé™¤',
                'keep_oldest': 'æœ€å¤å±¥æ­´ã®ã¿ä¿æŒ',
                'remove_oldest': 'æœ€å¤å±¥æ­´ã®ã¿å‰Šé™¤',
                'keep_by_date': f'{args.target_date}ã®å±¥æ­´ã®ã¿ä¿æŒ',
                'remove_by_date': f'{args.target_date}ã®å±¥æ­´ã®ã¿å‰Šé™¤',
                'keep_all': 'å…¨å±¥æ­´ä¿æŒ'
            }
            description = mode_descriptions.get(reset_mode, reset_mode)
            print(f"âœ… å±¥æ­´ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚»ãƒƒãƒˆï¼ˆ{description}ï¼‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
        else:
            print("âŒ å±¥æ­´ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚»ãƒƒãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
        return
    
    # é€šå¸¸ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†
    success = scraper.scrape_and_accumulate()
    
    if success:
        print("âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‹ç©ã¿ä¸Šã’ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
    else:
        print("âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)


if __name__ == "__main__":
    main()
